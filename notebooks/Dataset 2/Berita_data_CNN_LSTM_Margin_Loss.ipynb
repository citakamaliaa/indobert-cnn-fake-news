{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABGVQ8eXDRbf"
      },
      "source": [
        "##Install Library and preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkObFLTp1iz8",
        "outputId": "6afda9a7-3ec2-4da2-c922-c86daf028273",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting tf\n",
            "  Downloading tf-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cryptography>43 in /usr/local/lib/python3.12/dist-packages (from tf) (43.0.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.12/dist-packages (from tf) (1.76.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tf) (1.1.2)\n",
            "Requirement already satisfied: protobuf<6.0.0,>=5.28.3 in /usr/local/lib/python3.12/dist-packages (from tf) (5.29.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>43->tf) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.67.1->tf) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>43->tf) (2.23)\n",
            "Downloading tf-1.1.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf\n",
            "Successfully installed tf-1.1.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.9.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install tf\n",
        "!pip install -q gdown\n",
        "!pip install transformers[torch] accelerate -U\n",
        "!pip install accelerate -U\n",
        "!pip install datasets\n",
        "!pip install gensim\n",
        "!pip install evaluate\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,Trainer, AutoConfig, TrainingArguments, EarlyStoppingCallback\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Dense, Flatten, concatenate, BatchNormalization,LSTM, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import backend as K\n",
        "from evaluate import load\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import BorderlineSMOTE,KMeansSMOTE,SVMSMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGQpsv28XvR"
      },
      "source": [
        "###Read Dataset and load Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NRmM4a2V8SMH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/news_train_balanced_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "29E0Gp6E9EjI"
      },
      "outputs": [],
      "source": [
        "df_test1 = pd.read_csv(\"/content/news_test_clean.csv\")\n",
        "# df_test2 = pd.read_csv(\"test_data_2.csv\")\n",
        "# df_test3 = pd.read_csv(\"test_data_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0H49JgI8TY9",
        "outputId": "9e23d19b-d4c5-4b0a-82b1-cee7bb5d10b7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.4.0\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QYj5FruufaPq2mZgC6lZlq2Uw2E004Og\n",
            "To: /content/idwiki_word2vec_768_new_lower.model\n",
            "100% 14.4M/14.4M [00:00<00:00, 329MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1F9QsHO7FPIPq3nL_I0zCkZFvq3OVcJrB\n",
            "From (redirected): https://drive.google.com/uc?id=1F9QsHO7FPIPq3nL_I0zCkZFvq3OVcJrB&confirm=t&uuid=7e28c0eb-266b-4ab6-9d8f-458fa265f8c7\n",
            "To: /content/idwiki_word2vec_768_new_lower.model.syn1neg.npy\n",
            "100% 1.37G/1.37G [00:05<00:00, 235MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1VUjxpH10baOw439V-YAAVVbtyI8iLgG5\n",
            "From (redirected): https://drive.google.com/uc?id=1VUjxpH10baOw439V-YAAVVbtyI8iLgG5&confirm=t&uuid=60d420a3-9d51-4696-ad3a-3ddb0ae1aa0c\n",
            "To: /content/idwiki_word2vec_768_new_lower.model.wv.vectors.npy\n",
            "100% 1.37G/1.37G [00:09<00:00, 150MB/s] \n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "gc.collect()\n",
        "print(gensim.__version__)\n",
        "# Load Pretrained Word Embeddings (Word2Vec)\n",
        "!gdown --id 1QYj5FruufaPq2mZgC6lZlq2Uw2E004Og\n",
        "!gdown --id 1F9QsHO7FPIPq3nL_I0zCkZFvq3OVcJrB\n",
        "!gdown --id 1VUjxpH10baOw439V-YAAVVbtyI8iLgG5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import gdown\n",
        "# import zipfile\n",
        "\n",
        "# '''https://drive.google.com/file/d/1R0Rq2oQEH4N1K7eXLvGkvKosR2rzxIw3/view?usp=sharing'''\n",
        "\n",
        "# file_id = '1R0Rq2oQEH4N1K7eXLvGkvKosR2rzxIw3'\n",
        "\n",
        "# url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# output_zip = 'model_w2v.zip'\n",
        "\n",
        "# if not os.path.exists('idwiki_word2vec_768_new_lower.model'):\n",
        "#     print(\"Downloading Model...\")\n",
        "#     gdown.download(url, output_zip, quiet=False)\n",
        "\n",
        "#     print(\"Extracting File...\")\n",
        "#     with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
        "#         zip_ref.extractall('/content/')\n",
        "#     print(\"Done.\")\n",
        "# else:\n",
        "#     print(\"Model Available\")\n"
      ],
      "metadata": {
        "id": "hKvPKW3qaipf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7V5pKC5r8UxS"
      },
      "outputs": [],
      "source": [
        "word_embeddings = Word2Vec.load('/content/idwiki_word2vec_768_new_lower.model')\n",
        "#word_embeddings = Word2Vec.load('/content/modelword2vec/idwiki_word2vec_768_new_lower.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ITIl6C8d36"
      },
      "source": [
        "###Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ukXOneJy8a9y"
      },
      "outputs": [],
      "source": [
        "x_train = df['Text']\n",
        "y_train = df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lv1xgrHu9A7P"
      },
      "outputs": [],
      "source": [
        "x_test1 = df_test1['Text']\n",
        "y_test1 = np.array(df_test1['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e6rF6eY19VCF"
      },
      "outputs": [],
      "source": [
        "# x_test2 = df_test2['Text']\n",
        "# y_test2 = np.array(df_test2['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fwQkhOQW9XR7"
      },
      "outputs": [],
      "source": [
        "# x_test3 = df_test3['Text']\n",
        "# y_test3 = np.array(df_test3['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku94tLiA8qaL"
      },
      "source": [
        "###Define Loss Function, Tokenization, Word Embeddings and Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vsjGgf8g8lPj"
      },
      "outputs": [],
      "source": [
        "# Define the margin loss function\n",
        "def margin_loss(y_true, y_pred):\n",
        "    margin = K.constant(0.1)\n",
        "    y_true_float = K.cast(y_true, dtype='float32')  # Convert y_true to float32\n",
        "    squared_difference_pos = K.square(K.maximum(0.9 - y_pred, 0))\n",
        "    squared_difference_neg = K.square(K.maximum(y_pred - 0.1, 0))\n",
        "    loss_pos = K.mean(y_true_float * squared_difference_pos)\n",
        "    loss_neg = K.mean((1 - y_true_float) * squared_difference_neg)\n",
        "    total_loss = loss_pos + lambda_val * loss_neg\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7_1vCUiv8lw2"
      },
      "outputs": [],
      "source": [
        "# Define the model architectures\n",
        "#embedding_dim = 300\n",
        "#max_sequence_length = 100\n",
        "lambda_val = 0.7  # Lambda value for margin loss\n",
        "#num_words = 100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Vagruo208m1g"
      },
      "outputs": [],
      "source": [
        "# Create word index\n",
        "word_index = {word: index + 1 for index, word in enumerate(word_embeddings.wv.index_to_key)}\n",
        "\n",
        "# Create embedding matrix\n",
        "embedding_dim = word_embeddings.vector_size\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in word_embeddings.wv:\n",
        "        embedding_vector = word_embeddings.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AKqRHljW8pUH"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=len(word_index) + 1, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(x_train.astype(str))\n",
        "\n",
        "# Convert text to sequences and pad\n",
        "x_train_sequences = tokenizer.texts_to_sequences(x_train.astype(str))\n",
        "# Convert all values in x_test1 to string before tokenization\n",
        "x_test_sequences1 = tokenizer.texts_to_sequences(x_test1.astype(str))\n",
        "\n",
        "# Determine max sequence length based on your data\n",
        "max_sequence_length = max(max(len(seq) for seq in x_train_sequences), max(len(seq) for seq in x_test_sequences1))\n",
        "\n",
        "x_train_padded = pad_sequences(x_train_sequences, maxlen=max_sequence_length, padding='post')\n",
        "x_test_padded1 = pad_sequences(x_test_sequences1, maxlen=max_sequence_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pWMUC_FZuqis"
      },
      "outputs": [],
      "source": [
        "x_train_flat = x_train_padded.reshape(x_train_padded.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5t_kRh0x-4Y"
      },
      "source": [
        "####Oversampling with BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "I2n49516usxu"
      },
      "outputs": [],
      "source": [
        "borderline_smote = BorderlineSMOTE(random_state=42)\n",
        "x_train_resampled_flat_borderline, y_train_resampled_borderline = borderline_smote.fit_resample(x_train_flat, y_train)\n",
        "x_train_resampled_borderline = x_train_resampled_flat_borderline.reshape(x_train_resampled_flat_borderline.shape[0], max_sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jf8DgBkyFFt"
      },
      "source": [
        "####Oversampling with KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TS-SoVqLxoK7"
      },
      "outputs": [],
      "source": [
        "kmeans_smote = KMeansSMOTE(random_state=42, cluster_balance_threshold=0.2)\n",
        "x_train_resampled_flat_kmeans, y_train_resampled_kmeans = kmeans_smote.fit_resample(x_train_flat, y_train)\n",
        "x_train_resampled_kmeans = x_train_resampled_flat_kmeans.reshape(x_train_resampled_flat_kmeans.shape[0], max_sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "628lPkXdzjHU"
      },
      "source": [
        "####Oversampling with SVMSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lut9TruuyJNO"
      },
      "outputs": [],
      "source": [
        "svm_smote = SVMSMOTE(random_state=42)\n",
        "x_train_resampled_flat_svm, y_train_resampled_svm = svm_smote.fit_resample(x_train_flat, y_train)\n",
        "x_train_resampled_svm = x_train_resampled_flat_svm.reshape(x_train_resampled_flat_svm.shape[0], max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_pEO9YioEpmG",
        "outputId": "7c92554c-4d71-4cd4-9080-ed4e96e3276d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-4dSQpp8E6Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48648c9-db69-4928-8a87-3b652f788083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srm7SoyrBG4b"
      },
      "source": [
        "##CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LUfab0hDBIij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b27cec-91af-4597-fea5-41734b5eac78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define the architecture of the hybrid model with he_normal initialization\n",
        "static_input = Input(shape=(max_sequence_length,))\n",
        "static_embedding = Embedding(len(word_index) + 1, embedding_dim, input_length=max_sequence_length, trainable=False)(static_input)  # Removed weights parameter\n",
        "\n",
        "# CNN Layers\n",
        "static_cnn_output = Conv1D(128, 3, activation='relu', kernel_initializer=he_normal())(static_embedding)  # Use he_normal initialization\n",
        "static_cnn_output = MaxPooling1D(2)(static_cnn_output)\n",
        "static_cnn_output = GlobalMaxPooling1D()(static_cnn_output)\n",
        "static_cnn_output = Dropout(0.5)(static_cnn_output)\n",
        "batch_norm_layer_cnn = BatchNormalization()(static_cnn_output)\n",
        "\n",
        "# LSTM Layer\n",
        "static_lstm_output = LSTM(128, kernel_initializer=he_normal())(static_embedding)  # Use he_normal initialization\n",
        "static_lstm_output = Dropout(0.5)(static_lstm_output)\n",
        "batch_norm_layer_lstm = BatchNormalization()(static_lstm_output)\n",
        "\n",
        "# Concatenate CNN and LSTM outputs\n",
        "merged_layer = tf.keras.layers.concatenate([batch_norm_layer_cnn, batch_norm_layer_lstm], axis=-1)\n",
        "\n",
        "# Fully Connected Layers\n",
        "static_dense_output = Dense(128, activation='relu', kernel_initializer=he_normal())(merged_layer)  # Use he_normal initialization\n",
        "static_dense_output = Dropout(0.5)(static_dense_output)\n",
        "output = Dense(1, activation='sigmoid')(static_dense_output)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=static_input, outputs=output)\n",
        "hybrid_model.compile(optimizer='adam', loss=margin_loss, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CNN + LSTM BorderlineSMOTE Train and Test"
      ],
      "metadata": {
        "id": "y-D0d-2NJWaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj0cUXN3BJ6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c48d68-4a9b-45f5-9289-4b33df7e2c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 299ms/step - accuracy: 0.8100 - loss: 0.0764 - val_accuracy: 0.9979 - val_loss: 0.0165\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9820 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 3.8434e-06\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9920 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9962 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9963 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9975 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9969 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9976 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9976 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9981 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Train the CNN + LSTM model\n",
        "epochs_hybrid = 10\n",
        "history_hybrid_borderline = hybrid_model.fit(\n",
        "    x_train_resampled_borderline,\n",
        "    y_train_resampled_borderline,\n",
        "    batch_size=128,\n",
        "    epochs=epochs_hybrid,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to numpy arrays\n",
        "x_train_np = np.array(x_train_resampled_borderline)\n",
        "y_train_np = np.array(y_train_resampled_borderline)"
      ],
      "metadata": {
        "id": "-Xs1PQmvJP5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW-3qDDK-Nsh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Define the number of folds\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  # You can set a random seed for reproducibility\n",
        "\n",
        "# Initialize lists to store cross-validation results\n",
        "accuracies = []\n",
        "losses = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_q-JRbR-QRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ecaadf-8f25-4213-a52a-75ef1df6850a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 1/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 302ms/step - accuracy: 0.9971 - loss: 0.0013 - val_accuracy: 0.9992 - val_loss: 5.0174e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9974 - loss: 0.0011 - val_accuracy: 0.9989 - val_loss: 4.9613e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9981 - loss: 9.6813e-04 - val_accuracy: 0.9987 - val_loss: 6.4078e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9981 - loss: 9.0463e-04 - val_accuracy: 0.9992 - val_loss: 4.7846e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9981 - loss: 9.3934e-04 - val_accuracy: 0.9987 - val_loss: 6.1223e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9984 - loss: 7.9528e-04 - val_accuracy: 0.9984 - val_loss: 6.0273e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9986 - loss: 7.4353e-04 - val_accuracy: 0.9989 - val_loss: 5.6463e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 6.0430e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9984 - loss: 9.2907e-04\n",
            "Fold 1 - Training Loss: 0.00036919809645041823, Training Accuracy: 0.9993524551391602\n",
            "Fold 1 - Validation Loss: 0.0004784604534506798, Validation Accuracy: 0.9992052912712097\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1884\n",
            "           1       1.00      1.00      1.00      1891\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 2/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9978 - loss: 0.0010 - val_accuracy: 0.9995 - val_loss: 2.9994e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9980 - loss: 9.3508e-04 - val_accuracy: 0.9995 - val_loss: 2.9947e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.2413e-04 - val_accuracy: 0.9995 - val_loss: 2.9962e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.0843e-04 - val_accuracy: 0.9995 - val_loss: 2.9981e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 5.8193e-04 - val_accuracy: 0.9995 - val_loss: 3.0876e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 5.9730e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9983 - loss: 9.4917e-04\n",
            "Fold 2 - Training Loss: 0.00038270236109383404, Training Accuracy: 0.9993230104446411\n",
            "Fold 2 - Validation Loss: 0.0002994671813212335, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1895\n",
            "           1       1.00      1.00      1.00      1880\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 3/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 301ms/step - accuracy: 0.9982 - loss: 8.4161e-04 - val_accuracy: 0.9995 - val_loss: 3.1122e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 297ms/step - accuracy: 0.9981 - loss: 8.9833e-04 - val_accuracy: 0.9995 - val_loss: 2.9972e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9982 - loss: 7.6757e-04 - val_accuracy: 0.9995 - val_loss: 2.9965e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9980 - loss: 9.1022e-04 - val_accuracy: 0.9995 - val_loss: 3.0746e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9977 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 3.4565e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 6.8228e-04 - val_accuracy: 0.9992 - val_loss: 3.4220e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9988 - loss: 6.5696e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9991 - loss: 5.1666e-04\n",
            "Fold 3 - Training Loss: 0.00039762569940648973, Training Accuracy: 0.9992936253547668\n",
            "Fold 3 - Validation Loss: 0.0002996470720972866, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1862\n",
            "           1       1.00      1.00      1.00      1913\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 4/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9983 - loss: 7.9449e-04 - val_accuracy: 0.9995 - val_loss: 3.0154e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9982 - loss: 8.7960e-04 - val_accuracy: 0.9995 - val_loss: 3.1249e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9981 - loss: 9.3338e-04 - val_accuracy: 0.9995 - val_loss: 3.0311e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9981 - loss: 8.4789e-04 - val_accuracy: 0.9995 - val_loss: 3.0806e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9988 - loss: 6.6442e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9995 - loss: 3.1053e-04\n",
            "Fold 4 - Training Loss: 0.00038405059603974223, Training Accuracy: 0.9993230104446411\n",
            "Fold 4 - Validation Loss: 0.00030153628904372454, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1933\n",
            "           1       1.00      1.00      1.00      1842\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 5/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 301ms/step - accuracy: 0.9976 - loss: 0.0011 - val_accuracy: 0.9997 - val_loss: 1.5794e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9980 - loss: 9.6005e-04 - val_accuracy: 0.9997 - val_loss: 1.5245e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.7390e-04 - val_accuracy: 0.9997 - val_loss: 1.7682e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 7.0225e-04 - val_accuracy: 0.9995 - val_loss: 2.4694e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9981 - loss: 8.1351e-04 - val_accuracy: 0.9997 - val_loss: 1.5239e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 5.9375e-04 - val_accuracy: 0.9997 - val_loss: 1.6925e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9983 - loss: 8.2256e-04 - val_accuracy: 0.9997 - val_loss: 1.5684e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9979 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 2.3940e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9988 - loss: 6.5771e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9994 - loss: 3.6432e-04\n",
            "Fold 5 - Training Loss: 0.0004003021167591214, Training Accuracy: 0.9992936253547668\n",
            "Fold 5 - Validation Loss: 0.00015238820924423635, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1864\n",
            "           1       1.00      1.00      1.00      1911\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 6/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9988 - loss: 6.1024e-04 - val_accuracy: 0.9989 - val_loss: 5.9955e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9978 - loss: 0.0011 - val_accuracy: 0.9989 - val_loss: 5.9927e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 5.7672e-04 - val_accuracy: 0.9989 - val_loss: 6.0365e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 5.5971e-04 - val_accuracy: 0.9989 - val_loss: 5.9989e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9984 - loss: 6.5199e-04 - val_accuracy: 0.9989 - val_loss: 6.0423e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 6.0016e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9985 - loss: 8.3057e-04\n",
            "Fold 6 - Training Loss: 0.00034986535320058465, Training Accuracy: 0.9993818998336792\n",
            "Fold 6 - Validation Loss: 0.000599270046222955, Validation Accuracy: 0.9989404082298279\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1851\n",
            "           1       1.00      1.00      1.00      1924\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 7/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9988 - loss: 5.9790e-04 - val_accuracy: 0.9984 - val_loss: 8.9955e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 295ms/step - accuracy: 0.9988 - loss: 6.3657e-04 - val_accuracy: 0.9984 - val_loss: 8.9904e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9988 - loss: 5.1711e-04 - val_accuracy: 0.9984 - val_loss: 8.9966e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9990 - loss: 5.1291e-04 - val_accuracy: 0.9984 - val_loss: 8.9907e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9989 - loss: 5.8024e-04 - val_accuracy: 0.9984 - val_loss: 9.0000e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 5.4375e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9975 - loss: 0.0014\n",
            "Fold 7 - Training Loss: 0.00031630430021323264, Training Accuracy: 0.9994407892227173\n",
            "Fold 7 - Validation Loss: 0.000899040256626904, Validation Accuracy: 0.9984105825424194\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1876\n",
            "           1       1.00      1.00      1.00      1899\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 8/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.9981 - loss: 9.9873e-04 - val_accuracy: 0.9997 - val_loss: 1.4987e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 6.9028e-04 - val_accuracy: 0.9997 - val_loss: 1.5000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 6.2159e-04 - val_accuracy: 0.9997 - val_loss: 1.5003e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 6.3301e-04 - val_accuracy: 0.9997 - val_loss: 1.5083e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9988 - loss: 6.8509e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9998 - loss: 1.2221e-04\n",
            "Fold 8 - Training Loss: 0.0003996322338934988, Training Accuracy: 0.9992936253547668\n",
            "Fold 8 - Validation Loss: 0.00014987244503572583, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1907\n",
            "           1       1.00      1.00      1.00      1868\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 9/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9985 - loss: 6.9478e-04 - val_accuracy: 0.9997 - val_loss: 1.5000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9987 - loss: 6.8790e-04 - val_accuracy: 0.9997 - val_loss: 1.4996e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9988 - loss: 5.8137e-04 - val_accuracy: 0.9997 - val_loss: 1.4988e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 6.2225e-04 - val_accuracy: 0.9997 - val_loss: 1.4990e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9989 - loss: 5.2657e-04 - val_accuracy: 0.9997 - val_loss: 1.4953e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9983 - loss: 8.6633e-04 - val_accuracy: 0.9997 - val_loss: 1.5015e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 6.0957e-04 - val_accuracy: 0.9997 - val_loss: 1.5008e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 5.8116e-04 - val_accuracy: 0.9997 - val_loss: 1.4991e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 6.1559e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9996 - loss: 2.1248e-04\n",
            "Fold 9 - Training Loss: 0.0003821251157205552, Training Accuracy: 0.9993230104446411\n",
            "Fold 9 - Validation Loss: 0.0001495271862950176, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1930\n",
            "           1       1.00      1.00      1.00      1845\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 10/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9988 - loss: 6.3409e-04 - val_accuracy: 0.9992 - val_loss: 4.4996e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9985 - loss: 7.6297e-04 - val_accuracy: 0.9992 - val_loss: 4.4956e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9984 - loss: 6.8578e-04 - val_accuracy: 0.9992 - val_loss: 4.4952e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9985 - loss: 8.0520e-04 - val_accuracy: 0.9992 - val_loss: 4.5072e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9987 - loss: 6.7813e-04 - val_accuracy: 0.9992 - val_loss: 4.5150e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9986 - loss: 6.7328e-04 - val_accuracy: 0.9992 - val_loss: 4.4942e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9985 - loss: 6.9244e-04 - val_accuracy: 0.9992 - val_loss: 4.4949e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9990 - loss: 5.0002e-04 - val_accuracy: 0.9992 - val_loss: 4.4934e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9990 - loss: 4.7341e-04 - val_accuracy: 0.9992 - val_loss: 4.5044e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 5.9041e-04 - val_accuracy: 0.9992 - val_loss: 4.5011e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 5.5481e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9987 - loss: 7.5363e-04\n",
            "Fold 10 - Training Loss: 0.0003494843258522451, Training Accuracy: 0.9993818998336792\n",
            "Fold 10 - Validation Loss: 0.00044933700701221824, Validation Accuracy: 0.9992052912712097\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1873\n",
            "           1       1.00      1.00      1.00      1902\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store training and validation accuracies and losses\n",
        "train_accuracies_hybrid = []\n",
        "val_accuracies_hybrid = []\n",
        "train_losses_hybrid = []\n",
        "val_losses_hybrid = []\n",
        "classification_reports_hybrid = []\n",
        "# Iterate over the folds\n",
        "fold = 0\n",
        "for train_indices, val_indices in kf.split(x_train_np):\n",
        "    fold += 1\n",
        "    print(f\"Training fold {fold}/{num_folds}\")\n",
        "\n",
        "    hybrid_model = Model(inputs=static_input, outputs=output)\n",
        "\n",
        "    hybrid_model.compile(optimizer='adam', loss=margin_loss, metrics=['accuracy'])\n",
        "    # Get the training and validation data for this fold\n",
        "    x_train_fold = x_train_np[train_indices]\n",
        "    y_train_fold = y_train_np[train_indices]\n",
        "    x_val_fold = x_train_np[val_indices]\n",
        "    y_val_fold = y_train_np[val_indices]\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model for this fold\n",
        "    history = hybrid_model.fit(\n",
        "        x_train_fold,\n",
        "        y_train_fold,\n",
        "        batch_size=128,\n",
        "        epochs=epochs_hybrid,  # Make sure you define epochs_hybrid\n",
        "        validation_data=(x_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on this fold for training and validation\n",
        "    train_loss_hybrid, train_accuracy_hybrid = hybrid_model.evaluate(x_train_fold, y_train_fold)\n",
        "    val_loss_hybrid, val_accuracy_hybrid = hybrid_model.evaluate(x_val_fold, y_val_fold)\n",
        "\n",
        "    print(f\"Fold {fold} - Training Loss: {train_loss_hybrid}, Training Accuracy: {train_accuracy_hybrid}\")\n",
        "    print(f\"Fold {fold} - Validation Loss: {val_loss_hybrid}, Validation Accuracy: {val_accuracy_hybrid}\")\n",
        "\n",
        "    # Store the results for this fold\n",
        "    train_accuracies_hybrid.append(train_accuracy_hybrid)\n",
        "    val_accuracies_hybrid.append(val_accuracy_hybrid)\n",
        "    train_losses_hybrid.append(train_loss_hybrid)\n",
        "    val_losses_hybrid.append(val_loss_hybrid)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = (hybrid_model.predict(x_val_fold) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "    # Generate and store the classification report\n",
        "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
        "    classification_reports_hybrid.append(report)\n",
        "\n",
        "    # Print the classification report for this fold\n",
        "    print(classification_report(y_val_fold, y_pred))\n",
        "    print(\"-\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the mean and standard deviation of training accuracy and loss across folds\n",
        "mean_train_accuracy = sum(train_accuracies_hybrid) / num_folds\n",
        "std_train_accuracy = (sum([(acc - mean_train_accuracy) ** 2 for acc in train_accuracies_hybrid]) / num_folds) ** 0.5\n",
        "mean_train_loss = sum(train_losses_hybrid) / num_folds\n",
        "std_train_loss = (sum([(loss - mean_train_loss) ** 2 for loss in train_losses_hybrid]) / num_folds) ** 0.5\n",
        "print(f\"Mean Training Accuracy: {mean_train_accuracy}, Std Training Accuracy: {std_train_accuracy}\")\n",
        "print(f\"Mean Training Loss: {mean_train_loss}, Std Training Loss: {std_train_loss}\")\n",
        "\n",
        "# Calculate and print the mean and standard deviation of validation accuracy and loss across folds\n",
        "mean_val_accuracy = sum(val_accuracies_hybrid) / num_folds\n",
        "std_val_accuracy = (sum([(acc - mean_val_accuracy) ** 2 for acc in val_accuracies_hybrid]) / num_folds) ** 0.5\n",
        "mean_val_loss = sum(val_losses_hybrid) / num_folds\n",
        "std_val_loss = (sum([(loss - mean_val_loss) ** 2 for loss in val_losses_hybrid]) / num_folds) ** 0.5\n",
        "print(f\"Mean Validation Accuracy: {mean_val_accuracy}, Std Validation Accuracy: {std_val_accuracy}\")\n",
        "print(f\"Mean Validation Loss: {mean_val_loss}, Std Validation Loss: {std_val_loss}\")"
      ],
      "metadata": {
        "id": "ZiTmhpjZI8WZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab44bfd-7850-4115-b3f6-722637393555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Training Accuracy: 0.9993406951427459, Std Training Accuracy: 4.597577180771466e-05\n",
            "Mean Training Loss: 0.0003731290198629722, Std Training Loss: 2.5840888046477808e-05\n",
            "Mean Validation Accuracy: 0.9993377447128295, Std Validation Accuracy: 0.0003973563515544005\n",
            "Mean Validation Loss: 0.0003778546146349981, Std Validation Loss: 0.00022559264490831904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_report_hybrid = {\n",
        "    'Class 0': {\n",
        "        'precision': np.mean([r['0']['precision'] for r in classification_reports_hybrid]),\n",
        "        'recall': np.mean([r['0']['recall'] for r in classification_reports_hybrid]),\n",
        "        'f1-score': np.mean([r['0']['f1-score'] for r in classification_reports_hybrid]),\n",
        "        'support': np.sum([r['0']['support'] for r in classification_reports_hybrid])\n",
        "    },\n",
        "    'Class 1': {\n",
        "        'precision': np.mean([r['1']['precision'] for r in classification_reports_hybrid]),\n",
        "        'recall': np.mean([r['1']['recall'] for r in classification_reports_hybrid]),\n",
        "        'f1-score': np.mean([r['1']['f1-score'] for r in classification_reports_hybrid]),\n",
        "        'support': np.sum([r['1']['support'] for r in classification_reports_hybrid])\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print the aggregated classification report\n",
        "print(\"Average Classification Report across all folds:\")\n",
        "print(avg_report_hybrid)"
      ],
      "metadata": {
        "id": "6IawDHtaNAJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac121229-1219-47c7-81f1-4c09e6dcd5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Classification Report across all folds:\n",
            "{'Class 0': {'precision': np.float64(1.0), 'recall': np.float64(0.9986703463296493), 'f1-score': np.float64(0.9993345682415711), 'support': np.float64(18875.0)}, 'Class 1': {'precision': np.float64(0.9986825498222824), 'recall': np.float64(1.0), 'f1-score': np.float64(0.999340687685045), 'support': np.float64(18875.0)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EdrgaexFVVz"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define the file name for saving the metrics\n",
        "csv_file = 'metrics_hybrid_borderline.csv'\n",
        "\n",
        "headers = ['epoch', 'train_loss', 'train_accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "# Combine training and validation metrics into a single list\n",
        "all_metrics = []\n",
        "\n",
        "\n",
        "# Collect the metrics and populate the data\n",
        "for epoch in range(epochs_hybrid):\n",
        "    # Training metrics for the current epoch\n",
        "    train_loss = history_hybrid_borderline.history['loss'][epoch]\n",
        "    train_accuracy = history_hybrid_borderline.history['accuracy'][epoch]\n",
        "\n",
        "    # Validation metrics for the current epoch\n",
        "    val_loss = history_hybrid_borderline.history['val_loss'][epoch]\n",
        "    val_accuracy = history_hybrid_borderline.history['val_accuracy'][epoch]\n",
        "\n",
        "    # Append the metrics for the current epoch\n",
        "    all_metrics.append([epoch + 1, train_loss, train_accuracy, val_loss, val_accuracy])\n",
        "\n",
        "# Write the metrics to a CSV file\n",
        "with open(csv_file, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the headers\n",
        "    writer.writerow(headers)\n",
        "\n",
        "    # Write the data\n",
        "    writer.writerows(all_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESQEhnRjLEv1"
      },
      "source": [
        "####Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmVyV_gjLEv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d9395c-8ddc-4deb-da25-c4f4b986e7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m551/551\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 58ms/step - accuracy: 0.9553 - loss: 0.0194\n",
            "Hybrid Model Evaluation Results:\n",
            "Accuracy: 0.9641072154045105\n"
          ]
        }
      ],
      "source": [
        "hybrid_evaluation1 = hybrid_model.evaluate(x_test_padded1, y_test1, batch_size=4)\n",
        "hybrid_accuracy1 = hybrid_evaluation1[1]\n",
        "\n",
        "print(\"Hybrid Model Evaluation Results:\")\n",
        "print(\"Accuracy:\", hybrid_accuracy1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fLmqNy-LEv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc1e510-bb2f-4671-8e4c-67deba7b26c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step\n",
            "Classification Report on Test Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      2097\n",
            "           1       0.57      0.96      0.72       104\n",
            "\n",
            "    accuracy                           0.96      2201\n",
            "   macro avg       0.78      0.96      0.85      2201\n",
            "weighted avg       0.98      0.96      0.97      2201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_pred1 = (hybrid_model.predict(x_test_padded1) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "test_report1 = classification_report(y_test1, y_test_pred1)\n",
        "\n",
        "print(\"Classification Report on Test Dataset 1 :\")\n",
        "print(test_report1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CNN + LSTM KMeansSMOTE Train and Test"
      ],
      "metadata": {
        "id": "G9DPZTEyNIFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_model = Model(inputs=static_input, outputs=output)\n",
        "hybrid_model.compile(optimizer='adam', loss=margin_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gKXgb5W2NZWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a95vdt_3NIFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447fcea7-46c4-42c1-9d5c-33c3daa7a705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 294ms/step - accuracy: 0.9986 - loss: 7.5138e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.9816e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9984 - loss: 7.9450e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9986 - loss: 6.8618e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9987 - loss: 6.3222e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9992 - loss: 4.1615e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9988 - loss: 6.4570e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9987 - loss: 6.8554e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9988 - loss: 6.4700e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9986 - loss: 7.2609e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Train the CNN + LSTM model\n",
        "epochs_hybrid = 10\n",
        "history_hybrid_kmeans = hybrid_model.fit(\n",
        "    x_train_resampled_kmeans,\n",
        "    y_train_resampled_kmeans,\n",
        "    batch_size=128,\n",
        "    epochs=epochs_hybrid,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to numpy arrays\n",
        "x_train_np = np.array(x_train_resampled_kmeans)\n",
        "y_train_np = np.array(y_train_resampled_kmeans)"
      ],
      "metadata": {
        "id": "TZiHRw1CNIFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP-iZp__NIFO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Define the number of folds\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  # You can set a random seed for reproducibility\n",
        "\n",
        "# Initialize lists to store cross-validation results\n",
        "accuracies = []\n",
        "losses = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACyvgN3GNIFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d014e514-364b-4676-87be-7a70d74a2d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 1/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9992 - loss: 4.5828e-04 - val_accuracy: 0.9992 - val_loss: 3.5783e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 7.2955e-04 - val_accuracy: 0.9992 - val_loss: 3.7732e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9991 - loss: 4.3975e-04 - val_accuracy: 0.9995 - val_loss: 3.1229e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9985 - loss: 8.1593e-04 - val_accuracy: 0.9995 - val_loss: 2.9882e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9992 - loss: 4.1124e-04 - val_accuracy: 0.9995 - val_loss: 3.0013e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 7.8290e-04 - val_accuracy: 0.9995 - val_loss: 2.9957e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 5.9289e-04 - val_accuracy: 0.9992 - val_loss: 4.5393e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 5.9794e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9993 - loss: 3.6847e-04\n",
            "Fold 1 - Training Loss: 0.0003652214945759624, Training Accuracy: 0.9993524551391602\n",
            "Fold 1 - Validation Loss: 0.00029881755472160876, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1884\n",
            "           1       1.00      1.00      1.00      1891\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 2/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.9985 - loss: 8.2941e-04 - val_accuracy: 0.9995 - val_loss: 2.9962e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.5491e-04 - val_accuracy: 0.9995 - val_loss: 3.0004e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 6.4015e-04 - val_accuracy: 0.9995 - val_loss: 3.0008e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 6.2446e-04 - val_accuracy: 0.9995 - val_loss: 3.0002e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 5.4044e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9983 - loss: 9.4965e-04\n",
            "Fold 2 - Training Loss: 0.00036620136233977973, Training Accuracy: 0.9993524551391602\n",
            "Fold 2 - Validation Loss: 0.0002996192779392004, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1895\n",
            "           1       1.00      1.00      1.00      1880\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 3/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 301ms/step - accuracy: 0.9990 - loss: 5.3164e-04 - val_accuracy: 0.9995 - val_loss: 2.9983e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9987 - loss: 7.0624e-04 - val_accuracy: 0.9995 - val_loss: 2.9999e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9988 - loss: 5.8308e-04 - val_accuracy: 0.9995 - val_loss: 2.9976e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.0928e-04 - val_accuracy: 0.9995 - val_loss: 3.0007e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9991 - loss: 5.0052e-04 - val_accuracy: 0.9995 - val_loss: 2.9994e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9991 - loss: 5.0936e-04 - val_accuracy: 0.9995 - val_loss: 3.0007e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 5.8254e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9991 - loss: 5.1678e-04\n",
            "Fold 3 - Training Loss: 0.0003663676616270095, Training Accuracy: 0.9993524551391602\n",
            "Fold 3 - Validation Loss: 0.00029975533834658563, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1862\n",
            "           1       1.00      1.00      1.00      1913\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 4/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9992 - loss: 4.6423e-04 - val_accuracy: 0.9995 - val_loss: 2.9988e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9989 - loss: 5.7972e-04 - val_accuracy: 0.9995 - val_loss: 2.9949e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 6.3958e-04 - val_accuracy: 0.9995 - val_loss: 3.0007e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 7.0049e-04 - val_accuracy: 0.9995 - val_loss: 2.9977e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9992 - loss: 4.4866e-04 - val_accuracy: 0.9995 - val_loss: 2.9990e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 6.0513e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9995 - loss: 3.0691e-04\n",
            "Fold 4 - Training Loss: 0.0003660483635030687, Training Accuracy: 0.9993524551391602\n",
            "Fold 4 - Validation Loss: 0.00029949407326057553, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1933\n",
            "           1       1.00      1.00      1.00      1842\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 5/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9988 - loss: 6.9610e-04 - val_accuracy: 0.9997 - val_loss: 1.4980e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.8741e-04 - val_accuracy: 0.9997 - val_loss: 1.4984e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.9107e-04 - val_accuracy: 0.9997 - val_loss: 1.5003e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 7.0647e-04 - val_accuracy: 0.9997 - val_loss: 1.5012e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 5.9939e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9994 - loss: 3.6111e-04\n",
            "Fold 5 - Training Loss: 0.00038283903268165886, Training Accuracy: 0.9993230104446411\n",
            "Fold 5 - Validation Loss: 0.00014980463311076164, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1864\n",
            "           1       1.00      1.00      1.00      1911\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 6/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9992 - loss: 4.4189e-04 - val_accuracy: 0.9989 - val_loss: 5.9955e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9990 - loss: 4.5071e-04 - val_accuracy: 0.9989 - val_loss: 5.9856e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 4.9267e-04 - val_accuracy: 0.9989 - val_loss: 6.0047e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 7.4535e-04 - val_accuracy: 0.9989 - val_loss: 6.0047e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9990 - loss: 5.8010e-04 - val_accuracy: 0.9989 - val_loss: 5.9921e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 5.4733e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9985 - loss: 8.2956e-04\n",
            "Fold 6 - Training Loss: 0.00033253341098316014, Training Accuracy: 0.9994113445281982\n",
            "Fold 6 - Validation Loss: 0.0005985593888908625, Validation Accuracy: 0.9989404082298279\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1851\n",
            "           1       1.00      1.00      1.00      1924\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 7/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9990 - loss: 5.0907e-04 - val_accuracy: 0.9984 - val_loss: 8.9988e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9991 - loss: 5.3484e-04 - val_accuracy: 0.9984 - val_loss: 9.0095e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9989 - loss: 5.0157e-04 - val_accuracy: 0.9984 - val_loss: 8.9996e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 295ms/step - accuracy: 0.9986 - loss: 6.1704e-04 - val_accuracy: 0.9984 - val_loss: 8.9881e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9991 - loss: 4.6507e-04 - val_accuracy: 0.9984 - val_loss: 8.9940e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 295ms/step - accuracy: 0.9987 - loss: 7.1706e-04 - val_accuracy: 0.9984 - val_loss: 8.9651e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 295ms/step - accuracy: 0.9991 - loss: 4.2891e-04 - val_accuracy: 0.9984 - val_loss: 8.9307e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9990 - loss: 5.5611e-04 - val_accuracy: 0.9984 - val_loss: 8.9570e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9994 - loss: 3.0391e-04 - val_accuracy: 0.9984 - val_loss: 8.9849e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9987 - loss: 5.7624e-04 - val_accuracy: 0.9984 - val_loss: 8.9862e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9991 - loss: 4.8359e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9975 - loss: 0.0014\n",
            "Fold 7 - Training Loss: 0.00029769091634079814, Training Accuracy: 0.9994701743125916\n",
            "Fold 7 - Validation Loss: 0.0008930728072300553, Validation Accuracy: 0.9984105825424194\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1876\n",
            "           1       1.00      1.00      1.00      1899\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 8/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9987 - loss: 6.4250e-04 - val_accuracy: 0.9997 - val_loss: 1.4909e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9991 - loss: 5.0906e-04 - val_accuracy: 0.9997 - val_loss: 1.4904e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9992 - loss: 4.6003e-04 - val_accuracy: 0.9997 - val_loss: 1.4989e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9990 - loss: 5.5614e-04 - val_accuracy: 0.9997 - val_loss: 1.5001e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 6.1311e-04 - val_accuracy: 0.9997 - val_loss: 1.5008e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 6.2480e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9998 - loss: 1.2153e-04\n",
            "Fold 8 - Training Loss: 0.00038088331348262727, Training Accuracy: 0.9993230104446411\n",
            "Fold 8 - Validation Loss: 0.00014904131239745766, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1907\n",
            "           1       1.00      1.00      1.00      1868\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 9/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9990 - loss: 4.9665e-04 - val_accuracy: 0.9997 - val_loss: 1.4901e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9987 - loss: 6.1782e-04 - val_accuracy: 0.9997 - val_loss: 1.4978e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9990 - loss: 4.9547e-04 - val_accuracy: 0.9997 - val_loss: 1.4983e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9991 - loss: 4.5861e-04 - val_accuracy: 0.9997 - val_loss: 1.4917e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 6.1346e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9996 - loss: 2.1174e-04\n",
            "Fold 9 - Training Loss: 0.00038079917430877686, Training Accuracy: 0.9993230104446411\n",
            "Fold 9 - Validation Loss: 0.00014900833775755018, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1930\n",
            "           1       1.00      1.00      1.00      1845\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 10/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.9991 - loss: 4.9244e-04 - val_accuracy: 0.9992 - val_loss: 4.4924e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9993 - loss: 4.2033e-04 - val_accuracy: 0.9992 - val_loss: 4.4982e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9989 - loss: 4.8254e-04 - val_accuracy: 0.9992 - val_loss: 4.4909e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9990 - loss: 5.1781e-04 - val_accuracy: 0.9992 - val_loss: 4.4722e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9991 - loss: 4.1548e-04 - val_accuracy: 0.9992 - val_loss: 4.4929e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9990 - loss: 5.0801e-04 - val_accuracy: 0.9992 - val_loss: 4.4813e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9993 - loss: 3.7644e-04 - val_accuracy: 0.9992 - val_loss: 4.4898e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 5.5220e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9987 - loss: 7.5008e-04\n",
            "Fold 10 - Training Loss: 0.00034783751470968127, Training Accuracy: 0.9993818998336792\n",
            "Fold 10 - Validation Loss: 0.0004472195578273386, Validation Accuracy: 0.9992052912712097\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1873\n",
            "           1       1.00      1.00      1.00      1902\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store training and validation accuracies and losses\n",
        "train_accuracies_hybrid = []\n",
        "val_accuracies_hybrid = []\n",
        "train_losses_hybrid = []\n",
        "val_losses_hybrid = []\n",
        "classification_reports_hybrid = []\n",
        "# Iterate over the folds\n",
        "fold = 0\n",
        "for train_indices, val_indices in kf.split(x_train_np):\n",
        "    fold += 1\n",
        "    print(f\"Training fold {fold}/{num_folds}\")\n",
        "\n",
        "    hybrid_model = Model(inputs=static_input, outputs=output)\n",
        "\n",
        "    hybrid_model.compile(optimizer='adam', loss=margin_loss, metrics=['accuracy'])\n",
        "    # Get the training and validation data for this fold\n",
        "    x_train_fold = x_train_np[train_indices]\n",
        "    y_train_fold = y_train_np[train_indices]\n",
        "    x_val_fold = x_train_np[val_indices]\n",
        "    y_val_fold = y_train_np[val_indices]\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model for this fold\n",
        "    history = hybrid_model.fit(\n",
        "        x_train_fold,\n",
        "        y_train_fold,\n",
        "        batch_size=128,\n",
        "        epochs=epochs_hybrid,  # Make sure you define epochs_hybrid\n",
        "        validation_data=(x_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on this fold for training and validation\n",
        "    train_loss_hybrid, train_accuracy_hybrid = hybrid_model.evaluate(x_train_fold, y_train_fold)\n",
        "    val_loss_hybrid, val_accuracy_hybrid = hybrid_model.evaluate(x_val_fold, y_val_fold)\n",
        "\n",
        "    print(f\"Fold {fold} - Training Loss: {train_loss_hybrid}, Training Accuracy: {train_accuracy_hybrid}\")\n",
        "    print(f\"Fold {fold} - Validation Loss: {val_loss_hybrid}, Validation Accuracy: {val_accuracy_hybrid}\")\n",
        "\n",
        "    # Store the results for this fold\n",
        "    train_accuracies_hybrid.append(train_accuracy_hybrid)\n",
        "    val_accuracies_hybrid.append(val_accuracy_hybrid)\n",
        "    train_losses_hybrid.append(train_loss_hybrid)\n",
        "    val_losses_hybrid.append(val_loss_hybrid)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = (hybrid_model.predict(x_val_fold) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "    # Generate and store the classification report\n",
        "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
        "    classification_reports_hybrid.append(report)\n",
        "\n",
        "    # Print the classification report for this fold\n",
        "    print(classification_report(y_val_fold, y_pred))\n",
        "    print(\"-\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the mean and standard deviation of training accuracy and loss across folds\n",
        "mean_train_accuracy = sum(train_accuracies_hybrid) / num_folds\n",
        "std_train_accuracy = (sum([(acc - mean_train_accuracy) ** 2 for acc in train_accuracies_hybrid]) / num_folds) ** 0.5\n",
        "mean_train_loss = sum(train_losses_hybrid) / num_folds\n",
        "std_train_loss = (sum([(loss - mean_train_loss) ** 2 for loss in train_losses_hybrid]) / num_folds) ** 0.5\n",
        "print(f\"Mean Training Accuracy: {mean_train_accuracy}, Std Training Accuracy: {std_train_accuracy}\")\n",
        "print(f\"Mean Training Loss: {mean_train_loss}, Std Training Loss: {std_train_loss}\")\n",
        "\n",
        "# Calculate and print the mean and standard deviation of validation accuracy and loss across folds\n",
        "mean_val_accuracy = sum(val_accuracies_hybrid) / num_folds\n",
        "std_val_accuracy = (sum([(acc - mean_val_accuracy) ** 2 for acc in val_accuracies_hybrid]) / num_folds) ** 0.5\n",
        "mean_val_loss = sum(val_losses_hybrid) / num_folds\n",
        "std_val_loss = (sum([(loss - mean_val_loss) ** 2 for loss in val_losses_hybrid]) / num_folds) ** 0.5\n",
        "print(f\"Mean Validation Accuracy: {mean_val_accuracy}, Std Validation Accuracy: {std_val_accuracy}\")\n",
        "print(f\"Mean Validation Loss: {mean_val_loss}, Std Validation Loss: {std_val_loss}\")"
      ],
      "metadata": {
        "id": "X0PqFF1UNIFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d383dab-ba20-44b2-b6ad-b85847d0cd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Training Accuracy: 0.9993642270565033, Std Training Accuracy: 4.4054447785203437e-05\n",
            "Mean Training Loss: 0.0003586422244552523, Std Training Loss: 2.5098837596030833e-05\n",
            "Mean Validation Accuracy: 0.9993642330169678, Std Validation Accuracy: 0.0003964716992852376\n",
            "Mean Validation Loss: 0.0003584392281481996, Std Validation Loss: 0.00022283239044709247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_report_hybrid = {\n",
        "    'Class 0': {\n",
        "        'precision': np.mean([r['0']['precision'] for r in classification_reports_hybrid]),\n",
        "        'recall': np.mean([r['0']['recall'] for r in classification_reports_hybrid]),\n",
        "        'f1-score': np.mean([r['0']['f1-score'] for r in classification_reports_hybrid]),\n",
        "        'support': np.sum([r['0']['support'] for r in classification_reports_hybrid])\n",
        "    },\n",
        "    'Class 1': {\n",
        "        'precision': np.mean([r['1']['precision'] for r in classification_reports_hybrid]),\n",
        "        'recall': np.mean([r['1']['recall'] for r in classification_reports_hybrid]),\n",
        "        'f1-score': np.mean([r['1']['f1-score'] for r in classification_reports_hybrid]),\n",
        "        'support': np.sum([r['1']['support'] for r in classification_reports_hybrid])\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print the aggregated classification report\n",
        "print(\"Average Classification Report across all folds:\")\n",
        "print(avg_report_hybrid)"
      ],
      "metadata": {
        "id": "kj5ONJmONIFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697c7c68-f071-489a-8b87-ef64aa3dd0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Classification Report across all folds:\n",
            "{'Class 0': {'precision': np.float64(1.0), 'recall': np.float64(0.9987234248859126), 'f1-score': np.float64(0.9993611427719149), 'support': np.float64(18875.0)}, 'Class 1': {'precision': np.float64(0.9987352923500525), 'recall': np.float64(1.0), 'f1-score': np.float64(0.999367093800204), 'support': np.float64(18875.0)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpfzy2swNIFP"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define the file name for saving the metrics\n",
        "csv_file = 'metrics_hybrid_kmeans.csv'\n",
        "\n",
        "headers = ['epoch', 'train_loss', 'train_accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "# Combine training and validation metrics into a single list\n",
        "all_metrics = []\n",
        "\n",
        "\n",
        "# Collect the metrics and populate the data\n",
        "for epoch in range(epochs_hybrid):\n",
        "    # Training metrics for the current epoch\n",
        "    train_loss = history_hybrid_kmeans.history['loss'][epoch]\n",
        "    train_accuracy = history_hybrid_kmeans.history['accuracy'][epoch]\n",
        "\n",
        "    # Validation metrics for the current epoch\n",
        "    val_loss = history_hybrid_kmeans.history['val_loss'][epoch]\n",
        "    val_accuracy = history_hybrid_kmeans.history['val_accuracy'][epoch]\n",
        "\n",
        "    # Append the metrics for the current epoch\n",
        "    all_metrics.append([epoch + 1, train_loss, train_accuracy, val_loss, val_accuracy])\n",
        "\n",
        "# Write the metrics to a CSV file\n",
        "with open(csv_file, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the headers\n",
        "    writer.writerow(headers)\n",
        "\n",
        "    # Write the data\n",
        "    writer.writerows(all_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8lbgmrANIFP"
      },
      "source": [
        "####Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCD1YY-lNIFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2424536b-73d0-4b7f-e444-5f6e1fe412a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m551/551\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 57ms/step - accuracy: 0.9599 - loss: 0.0162\n",
            "Hybrid Model Evaluation Results:\n",
            "Accuracy: 0.9654702544212341\n"
          ]
        }
      ],
      "source": [
        "hybrid_evaluation1 = hybrid_model.evaluate(x_test_padded1, y_test1, batch_size=4)\n",
        "hybrid_accuracy1 = hybrid_evaluation1[1]\n",
        "\n",
        "print(\"Hybrid Model Evaluation Results:\")\n",
        "print(\"Accuracy:\", hybrid_accuracy1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFAyZZirNIFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8219ca27-75b1-492a-eae4-1d6f61ff8dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step\n",
            "Classification Report on Test Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98      2097\n",
            "           1       0.58      0.95      0.72       104\n",
            "\n",
            "    accuracy                           0.97      2201\n",
            "   macro avg       0.79      0.96      0.85      2201\n",
            "weighted avg       0.98      0.97      0.97      2201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_pred1 = (hybrid_model.predict(x_test_padded1) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "test_report1 = classification_report(y_test1, y_test_pred1)\n",
        "\n",
        "print(\"Classification Report on Test Dataset 1 :\")\n",
        "print(test_report1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CNN + LSTM SVMSMOTE Train and Test"
      ],
      "metadata": {
        "id": "3ktrAoWxOXeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_model = Model(inputs=static_input, outputs=output)\n",
        "hybrid_model.compile(optimizer='adam', loss=margin_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_2O0mVlKOXee"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ravOpOFIOXee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd7c66f-6e09-4202-bcec-fe0067a4e353",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 304ms/step - accuracy: 0.8143 - loss: 0.0760 - val_accuracy: 0.9995 - val_loss: 0.0177\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9801 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 2.5509e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9921 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9957 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9960 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9969 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9978 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9968 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9973 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9981 - loss: 9.0680e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Train the CNN + LSTM model\n",
        "epochs_hybrid = 10\n",
        "history_hybrid_svm = hybrid_model.fit(\n",
        "    x_train_resampled_svm,\n",
        "    y_train_resampled_svm,\n",
        "    batch_size=128,\n",
        "    epochs=epochs_hybrid,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to numpy arrays\n",
        "x_train_np = np.array(x_train_resampled_svm)\n",
        "y_train_np = np.array(y_train_resampled_svm)"
      ],
      "metadata": {
        "id": "Jy0dgos2OXee"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "erbo1kf_OXee"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Define the number of folds\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  # You can set a random seed for reproducibility\n",
        "\n",
        "# Initialize lists to store cross-validation results\n",
        "accuracies = []\n",
        "losses = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1qm337kbOXee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d7e012-e830-4748-8f05-971d23d2322e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 1/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 302ms/step - accuracy: 0.9976 - loss: 0.0011 - val_accuracy: 0.9989 - val_loss: 4.6494e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9972 - loss: 0.0014 - val_accuracy: 0.9987 - val_loss: 5.9683e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9973 - loss: 0.0013 - val_accuracy: 0.9984 - val_loss: 7.7993e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9978 - loss: 0.0011 - val_accuracy: 0.9984 - val_loss: 5.8233e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 50ms/step - accuracy: 0.9989 - loss: 6.1626e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9981 - loss: 8.7694e-04\n",
            "Fold 1 - Training Loss: 0.00037181604420766234, Training Accuracy: 0.9993524551391602\n",
            "Fold 1 - Validation Loss: 0.00046494207344949245, Validation Accuracy: 0.9989404082298279\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1884\n",
            "           1       1.00      1.00      1.00      1891\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 2/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9974 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 3.0559e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9973 - loss: 0.0013 - val_accuracy: 0.9989 - val_loss: 4.2045e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9976 - loss: 0.0010 - val_accuracy: 0.9995 - val_loss: 3.4438e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 295ms/step - accuracy: 0.9987 - loss: 6.1312e-04 - val_accuracy: 0.9995 - val_loss: 3.0344e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9980 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 3.4060e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9974 - loss: 0.0012 - val_accuracy: 0.9992 - val_loss: 3.7267e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9986 - loss: 5.8518e-04 - val_accuracy: 0.9995 - val_loss: 3.2204e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 51ms/step - accuracy: 0.9989 - loss: 6.0265e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9983 - loss: 9.5141e-04\n",
            "Fold 2 - Training Loss: 0.00038533349288627505, Training Accuracy: 0.9992936253547668\n",
            "Fold 2 - Validation Loss: 0.00030344215338118374, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1895\n",
            "           1       1.00      1.00      1.00      1880\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 3/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9981 - loss: 9.0691e-04 - val_accuracy: 0.9995 - val_loss: 2.9948e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9980 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 2.9965e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9980 - loss: 8.7226e-04 - val_accuracy: 0.9995 - val_loss: 3.0077e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9980 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 3.9385e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.9989 - loss: 6.3916e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9991 - loss: 5.1631e-04\n",
            "Fold 3 - Training Loss: 0.00038272375240921974, Training Accuracy: 0.9993230104446411\n",
            "Fold 3 - Validation Loss: 0.0002994837414007634, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1862\n",
            "           1       1.00      1.00      1.00      1913\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 4/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.9975 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 2.9960e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9983 - loss: 9.6223e-04 - val_accuracy: 0.9995 - val_loss: 2.9869e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 294ms/step - accuracy: 0.9981 - loss: 9.2633e-04 - val_accuracy: 0.9995 - val_loss: 3.0001e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9984 - loss: 7.8156e-04 - val_accuracy: 0.9995 - val_loss: 3.0343e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.8102e-04 - val_accuracy: 0.9992 - val_loss: 3.7264e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.9988 - loss: 6.6101e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9995 - loss: 3.0609e-04\n",
            "Fold 4 - Training Loss: 0.0003820675774477422, Training Accuracy: 0.9993230104446411\n",
            "Fold 4 - Validation Loss: 0.0002986907784361392, Validation Accuracy: 0.9994701743125916\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1933\n",
            "           1       1.00      1.00      1.00      1842\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 5/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9981 - loss: 0.0010 - val_accuracy: 0.9997 - val_loss: 1.7459e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9985 - loss: 8.0878e-04 - val_accuracy: 0.9997 - val_loss: 1.7400e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9984 - loss: 8.0455e-04 - val_accuracy: 0.9997 - val_loss: 1.5180e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9980 - loss: 0.0010 - val_accuracy: 0.9997 - val_loss: 1.6409e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9983 - loss: 7.9128e-04 - val_accuracy: 0.9995 - val_loss: 1.9466e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.4968e-04 - val_accuracy: 0.9995 - val_loss: 1.8487e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.9988 - loss: 6.5899e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9994 - loss: 3.6284e-04\n",
            "Fold 5 - Training Loss: 0.0004019395273644477, Training Accuracy: 0.9992936253547668\n",
            "Fold 5 - Validation Loss: 0.0001517986529506743, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1864\n",
            "           1       1.00      1.00      1.00      1911\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 6/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9985 - loss: 6.9256e-04 - val_accuracy: 0.9989 - val_loss: 5.9835e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 7.0588e-04 - val_accuracy: 0.9989 - val_loss: 5.9953e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9986 - loss: 8.2717e-04 - val_accuracy: 0.9989 - val_loss: 5.9393e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9983 - loss: 7.7777e-04 - val_accuracy: 0.9989 - val_loss: 6.3085e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.9063e-04 - val_accuracy: 0.9989 - val_loss: 5.9728e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9984 - loss: 7.3015e-04 - val_accuracy: 0.9989 - val_loss: 5.9797e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 50ms/step - accuracy: 0.9989 - loss: 6.0024e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9985 - loss: 8.2314e-04\n",
            "Fold 6 - Training Loss: 0.0003466471389401704, Training Accuracy: 0.9993818998336792\n",
            "Fold 6 - Validation Loss: 0.0005939266411587596, Validation Accuracy: 0.9989404082298279\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1851\n",
            "           1       1.00      1.00      1.00      1924\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 7/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9987 - loss: 6.8349e-04 - val_accuracy: 0.9984 - val_loss: 8.9847e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.1598e-04 - val_accuracy: 0.9984 - val_loss: 9.0231e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.2900e-04 - val_accuracy: 0.9984 - val_loss: 9.0719e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 5.6558e-04 - val_accuracy: 0.9984 - val_loss: 8.9868e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 51ms/step - accuracy: 0.9990 - loss: 5.4437e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9975 - loss: 0.0014\n",
            "Fold 7 - Training Loss: 0.00031686227885074914, Training Accuracy: 0.9994407892227173\n",
            "Fold 7 - Validation Loss: 0.0008984677260741591, Validation Accuracy: 0.9984105825424194\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1876\n",
            "           1       1.00      1.00      1.00      1899\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 8/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9986 - loss: 7.6410e-04 - val_accuracy: 0.9997 - val_loss: 1.4992e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9988 - loss: 6.4175e-04 - val_accuracy: 0.9997 - val_loss: 1.5012e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9986 - loss: 7.4128e-04 - val_accuracy: 0.9997 - val_loss: 1.5286e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9990 - loss: 5.5789e-04 - val_accuracy: 0.9997 - val_loss: 1.4956e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9986 - loss: 7.0073e-04 - val_accuracy: 0.9997 - val_loss: 1.6144e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9987 - loss: 6.8267e-04 - val_accuracy: 0.9997 - val_loss: 1.4940e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.3196e-04 - val_accuracy: 0.9997 - val_loss: 1.4958e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9993 - loss: 3.8040e-04 - val_accuracy: 0.9997 - val_loss: 1.5181e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9987 - loss: 6.0876e-04 - val_accuracy: 0.9997 - val_loss: 1.4850e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 6.6547e-04 - val_accuracy: 0.9997 - val_loss: 1.4925e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.9988 - loss: 6.8015e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9998 - loss: 1.2109e-04\n",
            "Fold 8 - Training Loss: 0.00039617641596123576, Training Accuracy: 0.9992936253547668\n",
            "Fold 8 - Validation Loss: 0.00014849522267468274, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1907\n",
            "           1       1.00      1.00      1.00      1868\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 9/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 300ms/step - accuracy: 0.9986 - loss: 7.2047e-04 - val_accuracy: 0.9997 - val_loss: 1.4916e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9992 - loss: 4.4037e-04 - val_accuracy: 0.9997 - val_loss: 1.5255e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9988 - loss: 6.4661e-04 - val_accuracy: 0.9997 - val_loss: 1.4884e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 5.5290e-04 - val_accuracy: 0.9997 - val_loss: 1.7907e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9985 - loss: 7.3243e-04 - val_accuracy: 0.9997 - val_loss: 1.5189e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9991 - loss: 4.8719e-04 - val_accuracy: 0.9997 - val_loss: 1.5604e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 51ms/step - accuracy: 0.9988 - loss: 6.6939e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9996 - loss: 2.1151e-04\n",
            "Fold 9 - Training Loss: 0.0003969063691329211, Training Accuracy: 0.9992936253547668\n",
            "Fold 9 - Validation Loss: 0.00014884139818605036, Validation Accuracy: 0.9997351169586182\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1930\n",
            "           1       1.00      1.00      1.00      1845\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training fold 10/10\n",
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 299ms/step - accuracy: 0.9986 - loss: 6.9941e-04 - val_accuracy: 0.9992 - val_loss: 4.4986e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 295ms/step - accuracy: 0.9985 - loss: 7.5807e-04 - val_accuracy: 0.9992 - val_loss: 4.4939e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 296ms/step - accuracy: 0.9981 - loss: 9.2374e-04 - val_accuracy: 0.9992 - val_loss: 4.4833e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9986 - loss: 7.2058e-04 - val_accuracy: 0.9992 - val_loss: 4.4752e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9991 - loss: 4.6215e-04 - val_accuracy: 0.9992 - val_loss: 4.4486e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 292ms/step - accuracy: 0.9989 - loss: 5.7996e-04 - val_accuracy: 0.9992 - val_loss: 4.4795e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 295ms/step - accuracy: 0.9989 - loss: 6.0502e-04 - val_accuracy: 0.9992 - val_loss: 4.3927e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9992 - loss: 4.4844e-04 - val_accuracy: 0.9992 - val_loss: 4.3929e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9990 - loss: 4.9911e-04 - val_accuracy: 0.9992 - val_loss: 4.4192e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 293ms/step - accuracy: 0.9987 - loss: 7.5627e-04 - val_accuracy: 0.9992 - val_loss: 4.5480e-04\n",
            "\u001b[1m1062/1062\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 51ms/step - accuracy: 0.9989 - loss: 5.9953e-04\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9987 - loss: 7.3674e-04\n",
            "Fold 10 - Training Loss: 0.0003583432990126312, Training Accuracy: 0.9993524551391602\n",
            "Fold 10 - Validation Loss: 0.00043927037040703, Validation Accuracy: 0.9992052912712097\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1873\n",
            "           1       1.00      1.00      1.00      1902\n",
            "\n",
            "    accuracy                           1.00      3775\n",
            "   macro avg       1.00      1.00      1.00      3775\n",
            "weighted avg       1.00      1.00      1.00      3775\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store training and validation accuracies and losses\n",
        "train_accuracies_hybrid = []\n",
        "val_accuracies_hybrid = []\n",
        "train_losses_hybrid = []\n",
        "val_losses_hybrid = []\n",
        "classification_reports_hybrid = []\n",
        "# Iterate over the folds\n",
        "fold = 0\n",
        "for train_indices, val_indices in kf.split(x_train_np):\n",
        "    fold += 1\n",
        "    print(f\"Training fold {fold}/{num_folds}\")\n",
        "\n",
        "    hybrid_model = Model(inputs=static_input, outputs=output)\n",
        "\n",
        "    hybrid_model.compile(optimizer='adam', loss=margin_loss, metrics=['accuracy'])\n",
        "    # Get the training and validation data for this fold\n",
        "    x_train_fold = x_train_np[train_indices]\n",
        "    y_train_fold = y_train_np[train_indices]\n",
        "    x_val_fold = x_train_np[val_indices]\n",
        "    y_val_fold = y_train_np[val_indices]\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model for this fold\n",
        "    history = hybrid_model.fit(\n",
        "        x_train_fold,\n",
        "        y_train_fold,\n",
        "        batch_size=128,\n",
        "        epochs=epochs_hybrid,  # Make sure you define epochs_hybrid\n",
        "        validation_data=(x_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on this fold for training and validation\n",
        "    train_loss_hybrid, train_accuracy_hybrid = hybrid_model.evaluate(x_train_fold, y_train_fold)\n",
        "    val_loss_hybrid, val_accuracy_hybrid = hybrid_model.evaluate(x_val_fold, y_val_fold)\n",
        "\n",
        "    print(f\"Fold {fold} - Training Loss: {train_loss_hybrid}, Training Accuracy: {train_accuracy_hybrid}\")\n",
        "    print(f\"Fold {fold} - Validation Loss: {val_loss_hybrid}, Validation Accuracy: {val_accuracy_hybrid}\")\n",
        "\n",
        "    # Store the results for this fold\n",
        "    train_accuracies_hybrid.append(train_accuracy_hybrid)\n",
        "    val_accuracies_hybrid.append(val_accuracy_hybrid)\n",
        "    train_losses_hybrid.append(train_loss_hybrid)\n",
        "    val_losses_hybrid.append(val_loss_hybrid)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = (hybrid_model.predict(x_val_fold) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "    # Generate and store the classification report\n",
        "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
        "    classification_reports_hybrid.append(report)\n",
        "\n",
        "    # Print the classification report for this fold\n",
        "    print(classification_report(y_val_fold, y_pred))\n",
        "    print(\"-\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the mean and standard deviation of training accuracy and loss across folds\n",
        "mean_train_accuracy = sum(train_accuracies_hybrid) / num_folds\n",
        "std_train_accuracy = (sum([(acc - mean_train_accuracy) ** 2 for acc in train_accuracies_hybrid]) / num_folds) ** 0.5\n",
        "mean_train_loss = sum(train_losses_hybrid) / num_folds\n",
        "std_train_loss = (sum([(loss - mean_train_loss) ** 2 for loss in train_losses_hybrid]) / num_folds) ** 0.5\n",
        "print(f\"Mean Training Accuracy: {mean_train_accuracy}, Std Training Accuracy: {std_train_accuracy}\")\n",
        "print(f\"Mean Training Loss: {mean_train_loss}, Std Training Loss: {std_train_loss}\")\n",
        "\n",
        "# Calculate and print the mean and standard deviation of validation accuracy and loss across folds\n",
        "mean_val_accuracy = sum(val_accuracies_hybrid) / num_folds\n",
        "std_val_accuracy = (sum([(acc - mean_val_accuracy) ** 2 for acc in val_accuracies_hybrid]) / num_folds) ** 0.5\n",
        "mean_val_loss = sum(val_losses_hybrid) / num_folds\n",
        "std_val_loss = (sum([(loss - mean_val_loss) ** 2 for loss in val_losses_hybrid]) / num_folds) ** 0.5\n",
        "print(f\"Mean Validation Accuracy: {mean_val_accuracy}, Std Validation Accuracy: {std_val_accuracy}\")\n",
        "print(f\"Mean Validation Loss: {mean_val_loss}, Std Validation Loss: {std_val_loss}\")"
      ],
      "metadata": {
        "id": "yYmCViF6OXef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a22ba7-c16d-48a5-df50-89914e7926f6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Training Accuracy: 0.9993348121643066, Std Training Accuracy: 4.5972719012554485e-05\n",
            "Mean Training Loss: 0.00037388158962130545, Std Training Loss: 2.515831872141872e-05\n",
            "Mean Validation Accuracy: 0.9993112564086915, Std Validation Accuracy: 0.00041379182751382276\n",
            "Mean Validation Loss: 0.0003747358758118935, Std Validation Loss: 0.00022429538350010405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_report_hybrid = {\n",
        "    'Class 0': {\n",
        "        'precision': np.mean([r['0']['precision'] for r in classification_reports_hybrid]),\n",
        "        'recall': np.mean([r['0']['recall'] for r in classification_reports_hybrid]),\n",
        "        'f1-score': np.mean([r['0']['f1-score'] for r in classification_reports_hybrid]),\n",
        "        'support': np.sum([r['0']['support'] for r in classification_reports_hybrid])\n",
        "    },\n",
        "    'Class 1': {\n",
        "        'precision': np.mean([r['1']['precision'] for r in classification_reports_hybrid]),\n",
        "        'recall': np.mean([r['1']['recall'] for r in classification_reports_hybrid]),\n",
        "        'f1-score': np.mean([r['1']['f1-score'] for r in classification_reports_hybrid]),\n",
        "        'support': np.sum([r['1']['support'] for r in classification_reports_hybrid])\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print the aggregated classification report\n",
        "print(\"Average Classification Report across all folds:\")\n",
        "print(avg_report_hybrid)"
      ],
      "metadata": {
        "id": "QI9-Q_obOXef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b9c6e2-8b6c-42a9-e789-ae06d82eecdc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Classification Report across all folds:\n",
            "{'Class 0': {'precision': np.float64(1.0), 'recall': np.float64(0.998617267773386), 'f1-score': np.float64(0.9993079795908603), 'support': np.float64(18875.0)}, 'Class 1': {'precision': np.float64(0.9986298629594496), 'recall': np.float64(1.0), 'f1-score': np.float64(0.9993142955192335), 'support': np.float64(18875.0)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8gs84tv_OXef"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define the file name for saving the metrics\n",
        "csv_file = 'metrics_hybrid_svm.csv'\n",
        "\n",
        "headers = ['epoch', 'train_loss', 'train_accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "# Combine training and validation metrics into a single list\n",
        "all_metrics = []\n",
        "\n",
        "\n",
        "# Collect the metrics and populate the data\n",
        "for epoch in range(epochs_hybrid):\n",
        "    # Training metrics for the current epoch\n",
        "    train_loss = history_hybrid_svm.history['loss'][epoch]\n",
        "    train_accuracy = history_hybrid_svm.history['accuracy'][epoch]\n",
        "\n",
        "    # Validation metrics for the current epoch\n",
        "    val_loss = history_hybrid_svm.history['val_loss'][epoch]\n",
        "    val_accuracy = history_hybrid_svm.history['val_accuracy'][epoch]\n",
        "\n",
        "    # Append the metrics for the current epoch\n",
        "    all_metrics.append([epoch + 1, train_loss, train_accuracy, val_loss, val_accuracy])\n",
        "\n",
        "# Write the metrics to a CSV file\n",
        "with open(csv_file, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the headers\n",
        "    writer.writerow(headers)\n",
        "\n",
        "    # Write the data\n",
        "    writer.writerows(all_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiMKHP9QOXef"
      },
      "source": [
        "####Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DZoJr2g9OXeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0937e5fc-2346-4ea3-8bec-45c6cc31ae7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m551/551\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 55ms/step - accuracy: 0.9785 - loss: 0.0085\n",
            "Hybrid Model Evaluation Results:\n",
            "Accuracy: 0.9772830605506897\n"
          ]
        }
      ],
      "source": [
        "hybrid_evaluation1 = hybrid_model.evaluate(x_test_padded1, y_test1, batch_size=4)\n",
        "hybrid_accuracy1 = hybrid_evaluation1[1]\n",
        "\n",
        "print(\"Hybrid Model Evaluation Results:\")\n",
        "print(\"Accuracy:\", hybrid_accuracy1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UbpTL90QOXeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76e1bac-eb31-4ed8-9648-c91bf6c59130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
            "Classification Report on Test Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      2097\n",
            "           1       0.69      0.95      0.80       104\n",
            "\n",
            "    accuracy                           0.98      2201\n",
            "   macro avg       0.84      0.97      0.89      2201\n",
            "weighted avg       0.98      0.98      0.98      2201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_pred1 = (hybrid_model.predict(x_test_padded1) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "test_report1 = classification_report(y_test1, y_test_pred1)\n",
        "\n",
        "print(\"Classification Report on Test Dataset 1 :\")\n",
        "print(test_report1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrN1wtWwCmrM"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YDPMKdU1YFsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import KFold\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "        hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "        hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')"
      ],
      "metadata": {
        "id": "teYs-iDIbF4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KktwkrR1O4Tr"
      },
      "source": [
        "###Hybrid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BorderlineSMOTE"
      ],
      "metadata": {
        "id": "DnLeRy0bO4Tr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLQDXmsKO4Tr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_hybrid = history_hybrid_borderline.history['loss']\n",
        "val_loss_hybrid = history_hybrid_borderline.history['val_loss']\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, len(train_loss_hybrid) + 1), train_loss_hybrid, label='Training Loss')\n",
        "plt.plot(range(1, len(val_loss_hybrid) + 1), val_loss_hybrid, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Hybrid CNN+LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8hjunM1O4Ts"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy_hybrid = history_hybrid_borderline.history['accuracy']\n",
        "val_accuracy_hybrid = history_hybrid_borderline.history['val_accuracy']\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, len(accuracy_hybrid) + 1), accuracy_hybrid, label='Training Accuracy')\n",
        "plt.plot(range(1, len(val_accuracy_hybrid) + 1), val_accuracy_hybrid, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy Hybrid CNN+LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3PfWu2_O4Ts"
      },
      "outputs": [],
      "source": [
        "predictions_hybrid_1 = hybrid_model.predict(x_test_padded1)\n",
        "predicted_labels_hybrid_1 = (predictions_hybrid_1 > 0.5).astype(int)\n",
        "cm_hybrid_1 = confusion_matrix(y_test1,predicted_labels_hybrid_1)\n",
        "show_confusion_matrix(cm_hybrid_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####KMeansSMOTE"
      ],
      "metadata": {
        "id": "aET88lwRO4Ts"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPvQwcRsO4Ts"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_hybrid = history_hybrid_kmeans.history['loss']\n",
        "val_loss_hybrid = history_hybrid_kmeans.history['val_loss']\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, len(train_loss_hybrid) + 1), train_loss_hybrid, label='Training Loss')\n",
        "plt.plot(range(1, len(val_loss_hybrid) + 1), val_loss_hybrid, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Hybrid CNN+LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhhtpGJoO4Tt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy_hybrid = history_hybrid_kmeans.history['accuracy']\n",
        "val_accuracy_hybrid = history_hybrid_kmeans.history['val_accuracy']\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, len(accuracy_hybrid) + 1), accuracy_hybrid, label='Training Accuracy')\n",
        "plt.plot(range(1, len(val_accuracy_hybrid) + 1), val_accuracy_hybrid, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy Hybrid CNN+LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy_G2KvGO4Tt"
      },
      "outputs": [],
      "source": [
        "predictions_hybrid_1 = hybrid_model.predict(x_test_padded1)\n",
        "predicted_labels_hybrid_1 = (predictions_hybrid_1 > 0.5).astype(int)\n",
        "cm_hybrid_1 = confusion_matrix(y_test1,predicted_labels_hybrid_1)\n",
        "show_confusion_matrix(cm_hybrid_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SVMSMOTE"
      ],
      "metadata": {
        "id": "g6RL6YyaO4Tu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4SiT0n4O4Tu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_hybrid = history_hybrid_svm.history['loss']\n",
        "val_loss_hybrid = history_hybrid_svm.history['val_loss']\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, len(train_loss_hybrid) + 1), train_loss_hybrid, label='Training Loss')\n",
        "plt.plot(range(1, len(val_loss_hybrid) + 1), val_loss_hybrid, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Hybrid CNN+LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dNwtEZAO4Tu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy_hybrid = history_hybrid_svm.history['accuracy']\n",
        "val_accuracy_hybrid = history_hybrid_svm.history['val_accuracy']\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, len(accuracy_hybrid) + 1), accuracy_hybrid, label='Training Accuracy')\n",
        "plt.plot(range(1, len(val_accuracy_hybrid) + 1), val_accuracy_hybrid, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy Hybrid CNN+LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0reTg3EqO4Tu"
      },
      "outputs": [],
      "source": [
        "predictions_hybrid_1 = hybrid_model.predict(x_test_padded1)\n",
        "predicted_labels_hybrid_1 = (predictions_hybrid_1 > 0.5).astype(int)\n",
        "cm_hybrid_1 = confusion_matrix(y_test1,predicted_labels_hybrid_1)\n",
        "show_confusion_matrix(cm_hybrid_1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r CNNLSTMMarginLoss.zip ./* -x \"sample_data/*\""
      ],
      "metadata": {
        "id": "MLdYeVIontei"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "collapsed_sections": [
        "ABGVQ8eXDRbf",
        "y-D0d-2NJWaa",
        "G9DPZTEyNIFN",
        "3ktrAoWxOXeU",
        "rrN1wtWwCmrM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}